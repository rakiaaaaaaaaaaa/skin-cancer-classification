{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Complete Skin Cancer Detection with Deep CNN\n# Dataset: HAM10000 from Kaggle\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.applications import EfficientNetB3, ResNet50\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:50:28.937586Z","iopub.execute_input":"2025-08-21T02:50:28.937950Z","iopub.status.idle":"2025-08-21T02:51:01.022988Z","shell.execute_reply.started":"2025-08-21T02:50:28.937918Z","shell.execute_reply":"2025-08-21T02:51:01.022157Z"}},"outputs":[{"name":"stderr","text":"2025-08-21 02:50:34.931104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1755744635.313336      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1755744635.415900      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"DATASET_PATH = \"/kaggle/input/skin-cancer-mnist-ham10000\"\n\n# Load metadata\ndf = pd.read_csv(os.path.join(DATASET_PATH, \"HAM10000_metadata.csv\"))\nprint(df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:01.024291Z","iopub.execute_input":"2025-08-21T02:51:01.024868Z","iopub.status.idle":"2025-08-21T02:51:01.103257Z","shell.execute_reply.started":"2025-08-21T02:51:01.024847Z","shell.execute_reply":"2025-08-21T02:51:01.102661Z"}},"outputs":[{"name":"stdout","text":"     lesion_id      image_id   dx dx_type   age   sex localization\n0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# 1. DATASET CONFIGURATION\n# =============================================================================\n\nDATASET_PATH = \"/kaggle/input/skin-cancer-mnist-ham10000\"\nBATCH_SIZE = 16  # Reduced for Kaggle memory limits\nIMG_SIZE = 224\nEPOCHS = 30      # Reduced for quick testing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:01.103784Z","iopub.execute_input":"2025-08-21T02:51:01.103985Z","iopub.status.idle":"2025-08-21T02:51:01.107762Z","shell.execute_reply.started":"2025-08-21T02:51:01.103969Z","shell.execute_reply":"2025-08-21T02:51:01.107235Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# =============================================================================\n# 2. LOAD AND EXPLORE DATA\n# =============================================================================\n\nprint(\"ğŸ“Š Loading dataset...\")\ndf = pd.read_csv(os.path.join(DATASET_PATH, \"HAM10000_metadata.csv\"))\n\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"Classes: {df['dx'].value_counts()}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:01.109143Z","iopub.execute_input":"2025-08-21T02:51:01.109310Z","iopub.status.idle":"2025-08-21T02:51:01.155065Z","shell.execute_reply.started":"2025-08-21T02:51:01.109297Z","shell.execute_reply":"2025-08-21T02:51:01.154353Z"}},"outputs":[{"name":"stdout","text":"ğŸ“Š Loading dataset...\nDataset shape: (10015, 7)\nClasses: dx\nnv       6705\nmel      1113\nbkl      1099\nbcc       514\nakiec     327\nvasc      142\ndf        115\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Map class names\nclass_names = {\n    'akiec': 'Actinic Keratoses',\n    'bcc': 'Basal Cell Carcinoma', \n    'bkl': 'Benign Keratosis',\n    'df': 'Dermatofibroma',\n    'mel': 'Melanoma',\n    'nv': 'Melanocytic Nevi',\n    'vasc': 'Vascular Lesions'\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:01.155701Z","iopub.execute_input":"2025-08-21T02:51:01.155957Z","iopub.status.idle":"2025-08-21T02:51:01.159386Z","shell.execute_reply.started":"2025-08-21T02:51:01.155937Z","shell.execute_reply":"2025-08-21T02:51:01.158875Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# =============================================================================\n# 3. FIND IMAGES\n# =============================================================================\n\ndef find_image_files(dataset_path):\n    \"\"\"Find all image files in the dataset\"\"\"\n    image_files = {}\n    \n    for root, dirs, files in os.walk(dataset_path):\n        for file in files:\n            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n                image_id = file.split('.')[0]\n                image_files[image_id] = os.path.join(root, file)\n    \n    return image_files\n\nprint(\"ğŸ” Finding image files...\")\nimage_files = find_image_files(DATASET_PATH)\nprint(f\"Found {len(image_files)} image files\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:01.160013Z","iopub.execute_input":"2025-08-21T02:51:01.160264Z","iopub.status.idle":"2025-08-21T02:51:24.516487Z","shell.execute_reply.started":"2025-08-21T02:51:01.160240Z","shell.execute_reply":"2025-08-21T02:51:24.515886Z"}},"outputs":[{"name":"stdout","text":"ğŸ” Finding image files...\nFound 10015 image files\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Add image paths to dataframe\ndf['image_path'] = df['image_id'].map(image_files)\ndf = df.dropna(subset=['image_path'])  # Remove rows without images\nprint(f\"Dataset shape after matching with images: {df.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.517290Z","iopub.execute_input":"2025-08-21T02:51:24.517587Z","iopub.status.idle":"2025-08-21T02:51:24.551456Z","shell.execute_reply.started":"2025-08-21T02:51:24.517562Z","shell.execute_reply":"2025-08-21T02:51:24.550918Z"}},"outputs":[{"name":"stdout","text":"Dataset shape after matching with images: (10015, 8)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Encode labels\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['dx'])\nnum_classes = len(label_encoder.classes_)\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Label mapping: {dict(zip(label_encoder.classes_, range(num_classes)))}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.552073Z","iopub.execute_input":"2025-08-21T02:51:24.552261Z","iopub.status.idle":"2025-08-21T02:51:24.576579Z","shell.execute_reply.started":"2025-08-21T02:51:24.552245Z","shell.execute_reply":"2025-08-21T02:51:24.575984Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 7\nLabel mapping: {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Encode labels\nlabel_encoder = LabelEncoder()\ndf['label'] = label_encoder.fit_transform(df['dx'])\nnum_classes = len(label_encoder.classes_)\n\nprint(f\"Number of classes: {num_classes}\")\nprint(f\"Label mapping: {dict(zip(label_encoder.classes_, range(num_classes)))}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.577382Z","iopub.execute_input":"2025-08-21T02:51:24.577580Z","iopub.status.idle":"2025-08-21T02:51:24.596137Z","shell.execute_reply.started":"2025-08-21T02:51:24.577566Z","shell.execute_reply":"2025-08-21T02:51:24.595598Z"}},"outputs":[{"name":"stdout","text":"Number of classes: 7\nLabel mapping: {'akiec': 0, 'bcc': 1, 'bkl': 2, 'df': 3, 'mel': 4, 'nv': 5, 'vasc': 6}\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# 5. SIMPLE PREPROCESSING\n# =============================================================================\n\ndef preprocess_image(image_path, target_size=(224, 224)):\n    \"\"\"Simple but effective preprocessing\"\"\"\n    try:\n        # Load image\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        # Resize\n        img = cv2.resize(img, target_size)\n        \n        # Normalize\n        img = img.astype(np.float32) / 255.0\n        \n        return img\n    except:\n        # Return black image if loading fails\n        return np.zeros((*target_size, 3), dtype=np.float32)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.597987Z","iopub.execute_input":"2025-08-21T02:51:24.598473Z","iopub.status.idle":"2025-08-21T02:51:24.617707Z","shell.execute_reply.started":"2025-08-21T02:51:24.598456Z","shell.execute_reply":"2025-08-21T02:51:24.617276Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# 6. DATA GENERATOR\n# =============================================================================\n\nclass QuickDataGenerator(keras.utils.Sequence):\n    def __init__(self, dataframe, batch_size=32, shuffle=True, augment=False):\n        self.df = dataframe.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.augment = augment\n        self.indices = np.arange(len(self.df))\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.floor(len(self.df) / self.batch_size))\n    \n    def __getitem__(self, index):\n        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n        X, y = self._generate_batch(batch_indices)\n        return X, y\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    \n    def _generate_batch(self, batch_indices):\n        X = np.empty((self.batch_size, IMG_SIZE, IMG_SIZE, 3), dtype=np.float32)\n        y = np.empty((self.batch_size,), dtype=int)\n        \n        for i, idx in enumerate(batch_indices):\n            # Load and preprocess image\n            image_path = self.df.iloc[idx]['image_path']\n            image = preprocess_image(image_path, (IMG_SIZE, IMG_SIZE))\n            \n            # Simple augmentation for training\n            if self.augment and np.random.random() > 0.5:\n                # Random flip\n                if np.random.random() > 0.5:\n                    image = np.fliplr(image)\n                # Random rotation\n                if np.random.random() > 0.5:\n                    k = np.random.randint(1, 4)\n                    image = np.rot90(image, k)\n            \n            X[i] = image\n            y[i] = self.df.iloc[idx]['label']\n        \n        # Convert to categorical\n        y = keras.utils.to_categorical(y, num_classes=num_classes)\n        return X, y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.618576Z","iopub.execute_input":"2025-08-21T02:51:24.618834Z","iopub.status.idle":"2025-08-21T02:51:24.645940Z","shell.execute_reply.started":"2025-08-21T02:51:24.618812Z","shell.execute_reply":"2025-08-21T02:51:24.645389Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# 7. SPLIT DATA\n# =============================================================================\n\nprint(\"ğŸ”„ Splitting dataset...\")\ntrain_df, val_df = train_test_split(\n    df, test_size=0.2, random_state=42, stratify=df['label']\n)\n\nprint(f\"Train samples: {len(train_df)}\")\nprint(f\"Validation samples: {len(val_df)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.646557Z","iopub.execute_input":"2025-08-21T02:51:24.646849Z","iopub.status.idle":"2025-08-21T02:51:24.681482Z","shell.execute_reply.started":"2025-08-21T02:51:24.646826Z","shell.execute_reply":"2025-08-21T02:51:24.680734Z"}},"outputs":[{"name":"stdout","text":"ğŸ”„ Splitting dataset...\nTrain samples: 8012\nValidation samples: 2003\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Create generators\ntrain_gen = QuickDataGenerator(train_df, BATCH_SIZE, shuffle=True, augment=True)\nval_gen = QuickDataGenerator(val_df, BATCH_SIZE, shuffle=False, augment=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.682465Z","iopub.execute_input":"2025-08-21T02:51:24.682774Z","iopub.status.idle":"2025-08-21T02:51:24.687174Z","shell.execute_reply.started":"2025-08-21T02:51:24.682749Z","shell.execute_reply":"2025-08-21T02:51:24.686631Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# 8. CREATE MODEL\n# =============================================================================\n\nprint(\"ğŸ—ï¸ Building model...\")\n\ndef create_model():\n    # Load pre-trained EfficientNet\n    base_model = EfficientNetB3(\n        weights='imagenet',\n        include_top=False,\n        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n    )\n    \n    # Freeze base model\n    base_model.trainable = False\n    \n    # Add classification head\n    model = keras.Sequential([\n        base_model,\n        layers.GlobalAveragePooling2D(),\n        layers.Dropout(0.3),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.2),\n        layers.Dense(num_classes, activation='softmax')\n    ])\n    \n    return model\n\nmodel = create_model()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:24.687976Z","iopub.execute_input":"2025-08-21T02:51:24.688230Z","iopub.status.idle":"2025-08-21T02:51:29.486866Z","shell.execute_reply.started":"2025-08-21T02:51:24.688208Z","shell.execute_reply":"2025-08-21T02:51:29.486256Z"}},"outputs":[{"name":"stdout","text":"ğŸ—ï¸ Building model...\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1755744685.142090      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1755744685.142809      36 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n\u001b[1m43941136/43941136\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Compile model\nmodel.compile(\n    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nprint(f\"Model parameters: {model.count_params():,}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:29.487517Z","iopub.execute_input":"2025-08-21T02:51:29.487696Z","iopub.status.idle":"2025-08-21T02:51:29.502390Z","shell.execute_reply.started":"2025-08-21T02:51:29.487682Z","shell.execute_reply":"2025-08-21T02:51:29.501873Z"}},"outputs":[{"name":"stdout","text":"Model parameters: 10,981,174\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# 9. TRAIN MODEL\n# =============================================================================\n\nprint(\"ğŸ¯ Starting training...\")\n\n# Callbacks\ncallbacks = [\n    EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True),\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-7),\n    ModelCheckpoint('best_model.h5', monitor='val_accuracy', save_best_only=True)\n]\n\n# Train\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=EPOCHS,\n    callbacks=callbacks,\n    verbose=1\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-21T02:51:29.503053Z","iopub.execute_input":"2025-08-21T02:51:29.503252Z"}},"outputs":[{"name":"stdout","text":"ğŸ¯ Starting training...\nEpoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1755744713.876973      98 service.cc:148] XLA service 0x7e9ddc220590 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1755744713.878482      98 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1755744713.878502      98 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1755744716.982379      98 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m  2/500\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m27s\u001b[0m 55ms/step - accuracy: 0.5156 - loss: 1.7210   ","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1755744732.495458      98 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m235s\u001b[0m 385ms/step - accuracy: 0.6679 - loss: 1.2119 - val_accuracy: 0.6700 - val_loss: 1.1338 - learning_rate: 1.0000e-04\nEpoch 2/30\n\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 187ms/step - accuracy: 0.6659 - loss: 1.1650 - val_accuracy: 0.6700 - val_loss: 1.1289 - learning_rate: 1.0000e-04\nEpoch 3/30\n\u001b[1m500/500\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 187ms/step - accuracy: 0.6717 - loss: 1.1459 - val_accuracy: 0.6700 - val_loss: 1.1303 - learning_rate: 1.0000e-04\nEpoch 4/30\n\u001b[1m 33/500\u001b[0m \u001b[32mâ”\u001b[0m\u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m1:10\u001b[0m 151ms/step - accuracy: 0.6360 - loss: 1.2716","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# 10. VISUALIZE RESULTS\n# =============================================================================\n\nprint(\"ğŸ“Š Training completed! Visualizing results...\")\n\n# Plot training history\nplt.figure(figsize=(12, 4))\n\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'], label='Training Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.grid(True)\n\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend()\nplt.grid(True)\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 11. QUICK EVALUATION\n# =============================================================================\n\nprint(\"ğŸ” Quick evaluation...\")\n\n# Get predictions on validation set\nval_predictions = model.predict(val_gen)\nval_pred_classes = np.argmax(val_predictions, axis=1)\n\n# Get true labels\nval_true_classes = []\nfor i in range(len(val_gen)):\n    _, batch_y = val_gen[i]\n    val_true_classes.extend(np.argmax(batch_y, axis=1))\nval_true_classes = np.array(val_true_classes[:len(val_pred_classes)])\n\n# Classification report\nprint(\"Classification Report:\")\ntarget_names = [class_names[cls] for cls in label_encoder.classes_]\nprint(classification_report(val_true_classes, val_pred_classes, target_names=target_names))\n\n# Confusion matrix\ncm = confusion_matrix(val_true_classes, val_pred_classes)\nplt.figure(figsize=(10, 8))\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n            xticklabels=target_names, yticklabels=target_names)\nplt.title('Confusion Matrix')\nplt.ylabel('True Label')\nplt.xlabel('Predicted Label')\nplt.xticks(rotation=45)\nplt.yticks(rotation=0)\nplt.tight_layout()\nplt.show()\n\n# Final accuracy\nfinal_acc = max(history.history['val_accuracy'])\nprint(f\"\\nğŸ‰ Best Validation Accuracy: {final_acc:.4f} ({final_acc*100:.2f}%)\")\n\nprint(\"\\nâœ… Quick training completed successfully!\")\nprint(\"ğŸ’¡ For better results, run the full pipeline with more epochs and advanced preprocessing!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 12. SAMPLE PREDICTIONS\n# =============================================================================\n\nprint(\"ğŸ”® Sample predictions on validation data...\")\n\n# Get a few samples for prediction\nsample_indices = np.random.choice(len(val_df), 6, replace=False)\nfig, axes = plt.subplots(2, 3, figsize=(15, 10))\naxes = axes.ravel()\n\nfor i, idx in enumerate(sample_indices):\n    # Get sample\n    sample_row = val_df.iloc[idx]\n    image_path = sample_row['image_path']\n    true_label = sample_row['dx']\n    \n    # Load and preprocess image\n    img = preprocess_image(image_path)\n    img_batch = np.expand_dims(img, axis=0)\n    \n    # Predict\n    pred = model.predict(img_batch, verbose=0)[0]\n    pred_class_idx = np.argmax(pred)\n    pred_class = label_encoder.classes_[pred_class_idx]\n    confidence = pred[pred_class_idx]\n    \n    # Display\n    axes[i].imshow(img)\n    axes[i].set_title(f\"True: {true_label}\\nPred: {pred_class}\\nConf: {confidence:.3f}\")\n    axes[i].axis('off')\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.save(\"model.h5\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nprint(\"Saved files:\", os.listdir(\"./\"))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nimport shutil\n\n# Save and zip (smaller, avoids browser issues with large files)\nmodel.save(\"/kaggle/working/model.h5\")\nshutil.make_archive(\"/kaggle/working/model\", 'zip', \"/kaggle/working\", \"model.h5\")\n\n# Link for the zip\nFileLink(\"/kaggle/working/model.zip\")\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}